{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#have removed transform function, changed to relu6, iterations are 100, leak is 0.3 instead of 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "import scipy.misc\n",
    "import scipy\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains all the helper functions needed to save the images into the specified folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1]))\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the generator and discriminator functions. Both these functions are using the Tensorflow-slim lightweight library. This makes making, training and evaluating models easier in tensorflow. With the help of TF-slim, one can define complex networks in a single line, taking into consideration all the required parameters.\n",
    "\n",
    "The generator function is initially defining a fully connected network wherein the normalization function is batch_norm. Normalization is used to prevent neurons from saturating when inputs have varying scale and to help generalization. The activation function is ReLU6 i.e. Rectified Linear Unit layer which computes the rectified linear value 6 i.e. min(max(features,0),6). In general, relu activation function is better than any other such as sigmoid because it is computationally simpler in terms of forward and backward passes. Also, ReLU saturates only when the input is less than 0. After this, it uses 4 consecutive convolutional 2d transpositions to generate the final image from the given random vectors. It keeps reducing the number of outputs in every layer keeping the kernel size the same of [5,5].\n",
    "\n",
    "The discriminator function aims at producing probabilities from the given input images. The first 3 layers use convolutional 2d networks and the last layer uses a fully connected layer and sigmoid function to flatten out the answer. The ReLU function used here is the leaky relu which is a modified version of ReLU using a non-zero gradient for negative input. It helps to eliminate saturation which tends to hamper learning in deep networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    \n",
    "    zP = slim.fully_connected(z,4*4*256,normalizer_fn=slim.batch_norm, activation_fn=tf.nn.relu6,\\\n",
    "                              scope='g_project',weights_initializer=initializer)\n",
    "    zCon = tf.reshape(zP,[-1,4,4,256])\n",
    "    \n",
    "    gen1 = slim.convolution2d_transpose(zCon,num_outputs=64,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm, activation_fn=tf.nn.relu6,scope='g_conv1', weights_initializer=initializer)\n",
    "    \n",
    "    gen2 = slim.convolution2d_transpose(gen1,num_outputs=32,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu6,scope='g_conv2', weights_initializer=initializer)\n",
    "    \n",
    "    gen3 = slim.convolution2d_transpose(gen2,num_outputs=16,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm, activation_fn=tf.nn.relu6,scope='g_conv3', weights_initializer=initializer)\n",
    "    \n",
    "    g_out = slim.convolution2d_transpose(gen3,num_outputs=1,kernel_size=[32,32],padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=tf.nn.tanh, scope='g_out', weights_initializer=initializer)\n",
    "    \n",
    "    return g_out\n",
    "\n",
    "\n",
    "def discriminator(bottom, reuse=False):\n",
    "    \n",
    "    dis1 = slim.convolution2d(bottom,16,[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=lrelu, reuse=reuse,scope='d_conv1',weights_initializer=initializer)\n",
    "    \n",
    "    dis2 = slim.convolution2d(dis1,32,[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu, reuse=reuse,scope='d_conv2', weights_initializer=initializer)\n",
    "    \n",
    "    dis3 = slim.convolution2d(dis2,64,[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu, reuse=reuse,scope='d_conv3',weights_initializer=initializer)\n",
    "    \n",
    "    d_out = slim.fully_connected(slim.flatten(dis3),1,activation_fn=tf.nn.sigmoid,\\\n",
    "        reuse=reuse,scope='d_out', weights_initializer=initializer)\n",
    "    \n",
    "    return d_out\n",
    "\n",
    "\n",
    "def lrelu(x, leak=0.3, name=\"lrelu\"):\n",
    "     with tf.variable_scope(name):\n",
    "         f1 = 0.5 * (1 + leak)\n",
    "         f2 = 0.5 * (1 - leak)\n",
    "         return f1 * x + f2 * abs(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This GAN will be using the MNIST dataset containing images of handwritten digits in black and white. It has 60000 training and 10000 testing examples. The original images are 28 x 28 but have been resized to 32 x 32 for this network. An initial vector of size 100 is used for generating images. The optimization objective of the GAN is taken as negative because the loss has to be reduced.\n",
    "\n",
    "The Adam optimizer is being used here to train the GAN. This optimizer performs much better than other optimizers such as Gradient Descent. There are many reasons for this. It uses moving averages of the parameters enabling it to use larger effective step size and the algorithm (Kingma and Ba's Adam) will converge to this step size without fine tuning. Gradients are then calculated and applied to the generator and discriminator networks respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "z_size = 100\n",
    "\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "\n",
    "z_in = tf.placeholder(shape=[None,z_size],dtype=tf.float32) #Random vector\n",
    "real_in = tf.placeholder(shape=[None,32,32,1],dtype=tf.float32) #Real images\n",
    "\n",
    "Gz = generator(z_in)\n",
    "Dx = discriminator(real_in)\n",
    "Dg = discriminator(Gz,reuse=True)\n",
    "\n",
    "d_loss = -tf.reduce_mean(tf.log(Dx) + tf.log(1.-Dg))\n",
    "g_loss = -tf.reduce_mean(tf.log(Dg))\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "trainerD = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "trainerG = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "d_grads = trainerD.compute_gradients(d_loss,tvars[9:])\n",
    "g_grads = trainerG.compute_gradients(g_loss,tvars[0:9])\n",
    "\n",
    "update_D = trainerD.apply_gradients(d_grads)\n",
    "update_G = trainerG.apply_gradients(g_grads)\n",
    "\n",
    "loss_gen1 = []\n",
    "loss_dis1 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell runs the actual program and ensures calling of the generator and discriminator functions appropriately. It runs for 10000 iterations at the end of which images can be seen as discernible and able to be recognized. The batch size of 128 is taken which means 128 random vectors are created in every iteration. Every tenth iteration stores the generated images and every 1000th iteration stores the updated model which can be used in later stages. \n",
    "\n",
    "A 'batch_size' amount of images are taken, they are reshaped and padded to make them of size 32 x 32. Then the discriminator is called once and generator twice to make the GAN more robust. On running, it can be seen that the generator loss fluctuates slightly while the discriminator loss decreases. This means the model is learning to generate better and better images. This is also seen from the images that are created. The first few images are extremely random and hazy with absolutely no sign of digits. They are just greyish pixels. As the iterations increase, digits begin to be seen and utimately, at the end of all iterations, the images that result are very good in terms of digit visibility. Thus, the GANs seem to have learnt to generate images of handwritten digits!\n",
    "\n",
    "The progression of the images can be seen below.\n",
    "Iteration 1\n",
    "<img src=\"fig0.png\">    \n",
    "Iteration 700\n",
    "<img src=\"fig700.png\">\n",
    "Iteration 12360\n",
    "<img src=\"fig12360.png\">\n",
    "Iteration 16760\n",
    "<img src=\"fig16760.png\">\n",
    "Iteration 18860\n",
    "<img src=\"fig18860.png\">\n",
    "Iteration 20000\n",
    "<img src=\"fig20000.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-d49704dd4bdd>:6: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "iterations = 20000\n",
    "sample_directory = './figures'\n",
    "model_directory = './trainedModels'\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(iterations):\n",
    "        zs = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32)\n",
    "        xs,_ = mnist.train.next_batch(batch_size)\n",
    "        xs = (np.reshape(xs,[batch_size,28,28,1]) - 0.5) * 2.0\n",
    "        xs = np.lib.pad(xs, ((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=(-1, -1))\n",
    "        _,dLoss = sess.run([update_D,d_loss],feed_dict={z_in:zs,real_in:xs})\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs})\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs})\n",
    "        if i % 10 == 0:\n",
    "            loss_gen1.append(float(gLoss))\n",
    "            loss_dis1.append(float(dLoss))\n",
    "            z2 = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32)\n",
    "            newZ = sess.run(Gz,feed_dict={z_in:z2})\n",
    "            if not os.path.exists(sample_directory):\n",
    "                os.makedirs(sample_directory)\n",
    "            save_images(np.reshape(newZ[0:36],[36,32,32]),[6,6],sample_directory+'/fig'+str(i)+'.png')\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            saver.save(sess,model_directory+'/model-'+str(i)+'.cptk')\n",
    "print (\"Done\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
